model_name_or_path: "Vikhrmodels/Vikhr-Llama3.1-8B-Instruct-R-01-09-24"
dataset: "data/vikhr-llama-3.1-rm4-scored-answers-rs7-nw2-t0.8-pref.jsonl"
per_device_train_batch_size: 1
per_device_eval_batch_size: 1
num_train_epochs: 2
log_level: "info"
attn_implementation: "sdpa"
save_strategy: "steps"
save_steps: 50
save_total_limit: 20
learning_rate: 0.000005
lr_scheduler_type: cosine
loss_type: "sigmoid"
gradient_accumulation_steps: 8
gradient_checkpointing: True
logging_steps: 1
remove_unused_columns: True
dataloader_num_workers: 2
dataset_num_proc: 10
max_length: 8192
max_prompt_length: 4096
save_only_model: True
generate_eval_examples: False
test_size: 0.05
evaluation_strategy: "steps"
eval_steps: 50
run_name: "rpo-sigmoid-top-rs-llama-3.1-01-09-24-lora-64-qkvogudlm-b0.1-rpa-1.0"
output_dir: "models/rpo-sigmoid-top-rs-llama-3.1-01-09-24-lora-64-qkvogudlm-b0.1-rpa-1.0"
warmup_steps: 10
report_to: "wandb"
beta: 0.1
rpo_alpha: 1.0
reference_free: True
bf16: False
fp16: True
seed: 42
logging_first_step: True
use_peft: True
lora_task_type: CAUSAL_LM
lora_target_modules:
  - "k_proj"
  - "v_proj"
  - "q_proj"
  - "o_proj"
  - "gate_proj"
  - "up_proj"
  - "down_proj"
  - "lm_head"
lora_r: 64
lora_alpha: 64
pad_token: "<|reserved_special_token_0|>"
eos_token: "<|eot_id|>"
chat_template: "{{ bos_token }}{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n'+ message['content'] | trim + '<|eot_id|>' %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{% endif %}"
force_chat_template: False
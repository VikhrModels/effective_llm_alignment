model_name_or_path: "yandex/YandexGPT-5-Lite-8B-pretrain"
dataset:
  - "Vikhrmodels/GrandMaster-PRO-MAX"
  - "Vikhrmodels/Grounded-RAG-RU-v2"
train_only_on_completions: True
per_device_train_batch_size: 1
per_device_eval_batch_size: 1
num_train_epochs: 1.5
save_strategy: "steps"
save_steps: 400
save_total_limit: 6
learning_rate: 0.000005
gradient_accumulation_steps: 16
gradient_checkpointing: True
logging_steps: 1
remove_unused_columns: False
dataloader_num_workers: 40
save_only_model: True
generate_eval_examples: True
use_liger: True
max_seq_length: 16384
attn_implementation: "sdpa"
evaluation_strategy: "steps"
eval_steps: 500
run_name: "sft-grndmrag-YandexGPT-lora-256-qkvogudlm-v1"
output_dir: "checkpoints/sft-grndmrag-YandexGPT-lora-256-qkvogudlm-v1"
warmup_steps: 20
report_to: "wandb"
conversation_field: "conversation"
bf16: True
seed: 42
logging_first_step: True
use_peft: True
lora_target_modules:
  - "qkv_proj"
  - "o_proj"
  - "gate_up_proj"
  - "down_proj"
  - "lm_head"
lora_r: 256
lora_alpha: 256
pad_token: "[SPEC_TOKEN_1001]"
assistant_message_template: "<s>assistant\n"
eos_token: "</s>"
chat_template: "{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% for message in messages %}{{'<s>' + message['role'] + '\n' + message['content'] + '</s>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<s>assistant\n' }}{% endif %}"
force_chat_template: True

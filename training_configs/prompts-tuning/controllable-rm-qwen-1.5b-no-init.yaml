model_name_or_path: "Vikhrmodels/ControllableRM-Qwen2.5-1.5B"
dataset: "Vikhrmodels/rm_training_dataset_16_12_24"
dataset_ratio: 0.03
test_size: 0.1
per_device_train_batch_size: 8
per_device_eval_batch_size: 16
num_train_epochs: 5
save_strategy: "epoch"
evaluation_strategy: "epoch"
num_prompts: 1
dissim_coef: 0.0
gumbel_temp: 1.0
gumbel_noise_scale: 0.1
prompt_len: 96
fused_forward: True
save_steps: 360
eval_steps: 60
save_only_model: True
save_total_limit: 10
learning_rate: 0.001
weight_decay: 0.01
lr_scheduler_type: "constant"
warmup_ratio: 0.01
center_rewards_coefficient: 0.01
gradient_accumulation_steps: 8
gradient_checkpointing: True
logging_steps: 1
remove_unused_columns: False
dataloader_num_workers: 2
max_length: 16384
attn_implementation: "sdpa"
torch_compile: False
run_name: "controllable-rm-qwen-1.5b-prompts-optimization-np1-dc0.0-pl96-pi-gumbel-dynamic-no-init"
output_dir: "checkpoints/controllable-rm-qwen-1.5b-prompts-optimization-np1-dc0.0-pl96-pi-gumbel-dynamic-no-init"
report_to: "wandb"
bf16: True
fp16: False
seed: 42
logging_first_step: True
pad_token: "<|endoftext|>"
eos_token: "<|im_end|>"
chat_template: "{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|im_start|>' + message['role'] + '\n' + message['content'] | trim + '<|im_end|>' %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant<|im_end|>\n' }}{% endif %}"
force_chat_template: False